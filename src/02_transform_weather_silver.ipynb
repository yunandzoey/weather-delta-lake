{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fbb2662-a008-4971-87d6-f078e20d46a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------  (cell 1) Widgets & helpers\n",
    "dbutils.widgets.text(\"start_date\", \"\")\n",
    "dbutils.widgets.text(\"end_date\",   \"\")\n",
    "start = dbutils.widgets.get(\"start_date\") or None\n",
    "end   = dbutils.widgets.get(\"end_date\")   or None\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from datetime import date\n",
    "\n",
    "# COMMAND ----------  (cell 2) Read Bronze, de‑dup, optional date filter\n",
    "bronze_raw = spark.read.table(\"weather_bronze.hourly\")\n",
    "\n",
    "# drop exact duplicates (same ts + lat/lon)\n",
    "bronze = bronze_raw.dropDuplicates(\n",
    "    [\"timestamp_utc\", \"location_lat\", \"location_lon\"]\n",
    ")\n",
    "\n",
    "# optional backfill window\n",
    "if start or end:\n",
    "    bronze = bronze.filter(\n",
    "        (F.col(\"timestamp_utc\") >= F.lit(start) if start else F.lit(\"1900-01-01\")) &\n",
    "        (F.col(\"timestamp_utc\") <  F.lit(end)   if end   else F.lit(\"2999-12-31\"))\n",
    "    )\n",
    "\n",
    "# daily roll‑up\n",
    "df_daily = (\n",
    "    bronze\n",
    "    .withColumn(\"date\", F.to_date(\"timestamp_utc\"))\n",
    "    .groupBy(\"date\", \"location_lat\", \"location_lon\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"row_count\"),\n",
    "        F.avg(\"temp_c\").alias(\"avg_temp_c\"),\n",
    "        F.max(\"wind_speed_kmh\").alias(\"max_wind_kmh\"),\n",
    "        F.min(\"humidity_pct\").alias(\"min_humidity_pct\"),\n",
    "    )\n",
    "    .withColumn(\"process_ts\", F.current_timestamp())\n",
    ")\n",
    "\n",
    "# COMMAND ----------  (cell 3) Data‑quality expectations\n",
    "# Rule 1: coverage – finished days must have 24 rows; today can be ≤ 24\n",
    "df_daily = df_daily.withColumn(\n",
    "    \"expect_row_count_ok\",\n",
    "    F.when(\n",
    "        F.col(\"date\") < F.current_date(),\n",
    "        F.col(\"row_count\") == 24\n",
    "    ).otherwise(F.col(\"row_count\") <= 24)\n",
    ")\n",
    "\n",
    "# Rule 2: temperature range\n",
    "df_daily = df_daily.withColumn(\n",
    "    \"expect_temp_ok\", F.col(\"avg_temp_c\").between(-60, 60)\n",
    ")\n",
    "\n",
    "# Rule 3: humidity range\n",
    "df_daily = df_daily.withColumn(\n",
    "    \"expect_humidity_ok\", F.col(\"min_humidity_pct\").between(0, 100)\n",
    ")\n",
    "\n",
    "# Aggregate flag\n",
    "dq_cols = [c for c in df_daily.columns if c.startswith(\"expect_\")]\n",
    "df_daily = df_daily.withColumn(\n",
    "    \"dq_passed\",\n",
    "    F.expr(\" and \".join(c for c in dq_cols))\n",
    ")\n",
    "\n",
    "# COMMAND ----------  (cell 4) Upsert into Delta Silver (1 row per date + location)\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS weather_silver\")\n",
    "target = \"weather_silver.daily\"\n",
    "\n",
    "if not spark.catalog.tableExists(target):\n",
    "    # --- first run: simple write ---\n",
    "    (df_daily.write\n",
    "        .format(\"delta\")\n",
    "        .partitionBy(\"date\")\n",
    "        .saveAsTable(target))\n",
    "else:\n",
    "    # --- subsequent runs: MERGE (upsert) ---\n",
    "    tgt = DeltaTable.forName(spark, target)\n",
    "\n",
    "    (tgt.alias(\"t\")\n",
    "        .merge(\n",
    "            source=df_daily.alias(\"s\"),\n",
    "            condition=(\"\"\"\n",
    "                t.date          = s.date          AND\n",
    "                t.location_lat  = s.location_lat  AND\n",
    "                t.location_lon  = s.location_lon\n",
    "            \"\"\")\n",
    "        )\n",
    "        .whenMatchedUpdateAll()\n",
    "        .whenNotMatchedInsertAll()\n",
    "        .execute()\n",
    "    )\n",
    "\n",
    "# COMMAND ----------  (cell 5) Fail job if any DQ errors (so alerting fires)\n",
    "bad = df_daily.filter(~F.col(\"dq_passed\"))\n",
    "\n",
    "# bad.select(\n",
    "#     \"date\", \"row_count\", \"avg_temp_c\",\n",
    "#     \"expect_row_count_ok\", \"expect_temp_ok\", \"expect_humidity_ok\"\n",
    "# ).show(truncate=False)\n",
    "\n",
    "if bad.count() > 0:\n",
    "    raise ValueError(f\"Data‑quality failed for {bad.count()} day(s)\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_transform_weather_silver",
   "widgets": {
    "end_date": {
     "currentValue": "",
     "nuid": "45392a62-a75e-4567-bfbe-ab05ac6f3453",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "end_date",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "end_date",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "start_date": {
     "currentValue": "",
     "nuid": "74d1c7be-604a-4168-a936-8530bc2c7937",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "start_date",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "start_date",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
