{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bba187bd-5521-45ea-8010-fa9b987e3bdf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ---------- (cell 1) Maintenance: OPTIMIZE + Z-ORDER\n",
    "\n",
    "# Compact small files and cluster by location for faster queries\n",
    "spark.sql(\"\"\"\n",
    "OPTIMIZE weather_silver.daily\n",
    "ZORDER BY (location_lat, location_lon)\n",
    "\"\"\")\n",
    "\n",
    "# COMMAND ---------- (cell 2) Maintenance: VACUUM Old Files\n",
    "\n",
    "# Remove old snapshot files older than 7 days (safe for production)\n",
    "spark.sql(\"\"\"\n",
    "VACUUM weather_silver.daily RETAIN 168 HOURS\n",
    "\"\"\")\n",
    "\n",
    "# COMMAND ---------- (cell 3) Gold Table: Weekly Aggregates\n",
    "\n",
    "df_gold_weekly = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  date_trunc('week', date) AS week_start,\n",
    "  location_lat,\n",
    "  location_lon,\n",
    "  ROUND(AVG(avg_temp_c), 2) AS weekly_avg_temp,\n",
    "  MAX(max_wind_kmh) AS weekly_max_wind,\n",
    "  ROUND(AVG(min_humidity_pct), 2) AS weekly_avg_humidity,\n",
    "  COUNT(*) AS days_covered,\n",
    "  current_timestamp() AS process_ts\n",
    "FROM weather_silver.daily\n",
    "GROUP BY 1, 2, 3\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS weather_gold\")\n",
    "\n",
    "(df_gold_weekly.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .partitionBy(\"week_start\")\n",
    "    .saveAsTable(\"weather_gold.weekly\"))\n",
    "\n",
    "# COMMAND ---------- (cell 4) Gold Table: Monthly Aggregates\n",
    "\n",
    "df_gold_monthly = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  date_trunc('month', date) AS month_start,\n",
    "  location_lat,\n",
    "  location_lon,\n",
    "  ROUND(AVG(avg_temp_c), 2) AS monthly_avg_temp,\n",
    "  MAX(max_wind_kmh) AS monthly_max_wind,\n",
    "  ROUND(AVG(min_humidity_pct), 2) AS monthly_avg_humidity,\n",
    "  COUNT(*) AS days_covered,\n",
    "  current_timestamp() AS process_ts\n",
    "FROM weather_silver.daily\n",
    "GROUP BY 1, 2, 3\n",
    "\"\"\")\n",
    "\n",
    "(df_gold_monthly.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .partitionBy(\"month_start\")\n",
    "    .saveAsTable(\"weather_gold.monthly\"))\n",
    "\n",
    "# COMMAND ---------- (cell 5) Quick Checks\n",
    "\n",
    "print(\"Weekly Gold Preview:\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT * FROM weather_gold.weekly\n",
    "ORDER BY week_start DESC\n",
    "LIMIT 5\n",
    "\"\"\").show()\n",
    "\n",
    "print(\"Monthly Gold Preview:\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT * FROM weather_gold.monthly\n",
    "ORDER BY month_start DESC\n",
    "LIMIT 5\n",
    "\"\"\").show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "03_maintenance_gold_tables",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
